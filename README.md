# AIAR Guitar

> Browser-based Augmented Reality Guitar with Real-Time Computer Vision & AI Chord Correction

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Next.js](https://img.shields.io/badge/Next.js-15-black)](https://nextjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688)](https://fastapi.tiangolo.com/)

## Features

- ** Hand Tracking**: Real-time hand landmark detection using MediaPipe
- ** AR Guitar**: 3D guitar overlay that anchors to your body
- ** Audio Synthesis**: Low-latency Tone.js audio engine with strum detection
- ** AI Chord Correction**: Vector similarity search for accurate chord recognition
- ** Real-Time**: Sub-35ms frame-to-audio latency target

## ğŸš€ Quick Start

### Prerequisites

- Node.js 20+ and pnpm
- Python 3.11+
- Docker (for running Qdrant)

### Development Setup

```bash
# Clone the repository
git clone https://github.com/your-org/aiar-guitar.git
cd aiar-guitar

# Start all services with Docker Compose
docker-compose -f ops/docker-compose.yml up -d

# Or run services individually:

# Frontend (Terminal 1)
cd frontend
pnpm install
pnpm dev

# Backend (Terminal 2)
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Access the Application

- **Frontend**: <http://localhost:3000>
- **Backend API**: <http://localhost:8000>
- **API Docs**: <http://localhost:8000/docs>
- **Qdrant Dashboard**: <http://localhost:6333/dashboard>

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Browser (Client)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  MediaPipe   â”‚  â”‚   Three.js   â”‚  â”‚   Tone.js    â”‚      â”‚
â”‚  â”‚    Hands     â”‚  â”‚  AR Render   â”‚  â”‚    Audio     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                                     â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚          Zustand State Store                     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                     â”‚ WebSocket                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Backend Services                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   FastAPI    â”‚  â”‚    Chord     â”‚  â”‚   Qdrant     â”‚      â”‚
â”‚  â”‚  WebSocket   â”‚â”€â”€â”‚  Recognition â”‚â”€â”€â”‚  Vector DB   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
/
â”œâ”€â”€ frontend/               # Next.js 15 frontend
â”‚   â”œâ”€â”€ app/               # App Router pages
â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ Vision/        # Hand tracking
â”‚   â”‚   â”œâ”€â”€ AR/            # 3D rendering
â”‚   â”‚   â”œâ”€â”€ UI/            # UI components
â”‚   â”‚   â””â”€â”€ Debug/         # Debug overlays
â”‚   â”œâ”€â”€ systems/           # Audio engine
â”‚   â”œâ”€â”€ stores/            # Zustand state
â”‚   â””â”€â”€ types/             # TypeScript types
â”œâ”€â”€ backend/               # FastAPI backend
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ models/        # Pydantic models
â”‚       â”œâ”€â”€ services/      # Business logic
â”‚       â””â”€â”€ tests/         # Pytest tests
â”œâ”€â”€ ops/                   # DevOps configs
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ docs/                  # Documentation
â””â”€â”€ .github/workflows/     # CI/CD
```

## ğŸ® Usage

1. **Grant Camera Permission**: Allow the browser to access your webcam
2. **Position Yourself**: Stand in front of the camera with your arms visible
3. **Play**: Move your right hand across the virtual strings to strum
4. **Chord Positions**: Shape your left hand to form chords on the virtual fretboard

### Debug Mode

Add `?debug=true` to the URL to enable:

- Hand landmark visualization
- Strum velocity vectors
- Collision zone overlays
- FPS and latency metrics

## ğŸ”§ Configuration

### Environment Variables

```bash
# Frontend (.env.local)
NEXT_PUBLIC_WSS_URL=ws://localhost:8000/ws/inference

# Backend (.env)
QDRANT_URL=http://localhost:6333
EMBEDDING_MODE=raw        # "raw" (63D) or "mlp" (128D)
SCORE_THRESHOLD=0.85
OPENAI_API_KEY=           # Optional, for future features
```

## Documentation

- [Architecture Overview](./docs/ARCHITECTURE.md)
- [API Schema](./docs/API_SCHEMA.md)
- [Testing Guide](./docs/TESTING.md)
- [Deployment Guide](./docs/DEPLOY.md)

## Testing

```bash
# Frontend tests
cd frontend
pnpm test

# Backend tests
cd backend
pytest -v

# Smoke test (requires Docker)
./ops/smoke_test.sh
```

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'feat: add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- [MediaPipe](https://mediapipe.dev/) for hand tracking
- [Three.js](https://threejs.org/) and [React Three Fiber](https://docs.pmnd.rs/react-three-fiber)
- [Tone.js](https://tonejs.github.io/) for audio synthesis
- [Qdrant](https://qdrant.tech/) for vector similarity search
